# Tag 8

Wir haben noch einen kurzen Nachtrag zu LIDO erhalten: Der Standard ist echt gut und die ungewohnte Struktur soll nicht abschreckend wirken. Für Crosswalks gibt es – wie wir es schon kennen – Mapping-Dateien, wie zum Beispiel die folgende Excel-Datei:

```
https://www.smb.museum/fileadmin/website/Institute/Institut_fuer_Museumsforschung/Fachstelle_Museum/DDB-LIDO_1.9.xlsx
```

Auch zu Solr gab es noch einen kurzen Input: Wie bereits erwähnt ist Solr zusammen mit Elasticsearch die meistgenutzte Suchmaschine. Auch z.B. Ex Libris Primo nutzt Solr. Eine wirklich brauchbare Suchoberfläche wird bei Solr aber leider nicht mitgeliefert. Dafür braucht man beispielsweise das Discovery-System VuFind, was wir ja auch machen.

Die Solr-Benutzeroberfläche ist auf Port 8983, dort können viele Einstellungen angepasst werden. Es kann vorkommen, dass der Port nicht erreichbar ist. In diesem Falle muss wahrscheinlich Solr nochmals gestartet werden. Dies geht wie folgt:

```
cd /usr/local/vufind/
./solr.sh start
```

### Unterschied von Suchindex und Datenbank

#### Suchindex (Solr)
In einem Suchindex wie Solr sind Dokumente abgespeichert. Datenverarbeitung ist nicht oder nur schwer möglich. Trunkierung und simple Textsuche ist möglich, komplexe Suchanfragen aber nicht. Für komplexe Suchanfragen werden Datenbanken wie MySQL empfohlen. Da die suche lexikalisch ist und keine Konsistenzprüfung gemacht wird können auch ähnlich geschriebene Suchergebnisse erscheinen und es ist kein klassischer 1:1-Abgleich.

--> hauptsächlich für die Suche (Retrieval) geeignet
    
#### Datenbank (MySQL)
Bei Datenbanken wie MySQL geschieht hingegen ein 1:1-Abruf von eingegebenen Termen – also ein reiner Glyphenvergleich. Dies führt zu weniger guten Resultaten (ausser man will explizit eine exakte Suche, was aber in der Praxis selten vorkommt). MySQL funktioniert nach dem CRUD-Ansatz, das bedeutet "Create, Read, Update, Delete". Datensätze werden also persistent und konsistent abgespeichert und können anschliessend verwaltet werden. Dies beinhaltet lesen, updaten und/oder löschen.

--> hauptsächlich fürs abspeichern von Daten (Storage) geeignet.

###

![](https://raw.githubusercontent.com/remooda/bain/master/pictures/3.png)

Bei diesem Log sieht man die Gewichtung der einzelnen Felder.

Der Suchalgorithmus eines Discovery-Systems ist also gar nicht so komplex konfiguriert. Es basiert meist nur auf einer Gewichtung der einzelnen Felder.

Praxis (feinjustierung des Algorithmus)
Hauptnutzungsgruppen suchen
herausfinden, was wohl am meisten gesucht wird

Gewichtung ausprobieren
schauen, welche Gewichtung die besten Resultate bringt – anpassen bis man mit den Ergebnissen zufrieden ist

### Übung Import in Solr

Nun kommen wir zur Übung, für die wir uns schon lange vorbereitet haben – wir sollten nun die Dateien, die aus ArcivesSpace, DSpace und Koha exportiert wurden in die Suchmaschine Solr einspielen.

gedit /usr/local/vufind/import/marc_local.properties

Im Dokument, das mit dem obenstehenden Befehl aufgerufen werden kann, muss bei den unten abgebildeten drei auskommentierten Zeilen die Raute wieder entfernt werden:

collection = "ArchivesSpace"
institution = "ArchivesSpace"
building = "......"


VuFind nutzt das MARC-Feld 001 als ID. Wenn die Datei keine 001 hat, klappt der Import nicht. Wenn viele zu importierende Dateien keine 001 haben, würde ich OpenRefine verwenden, um das Feld bei allen Dateien auf einmal zu vergeben.